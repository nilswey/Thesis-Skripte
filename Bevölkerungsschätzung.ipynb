{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d6ff48-c628-4943-8cf0-3e89d31ee7a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor: Nils Weyrauch\\nSkript für die Erstellung des Bevölkerungsrasters auf Basis der Häuserklassifikation\\n\\nPackages:\\nGeopandas\\nPandas\\n\\nAufbau:\\n1. Ermittlung der prozentualen Anteile der Häuserklassen an den 100m Grid Zellen\\n2. Identifizierung geeigneter Kacheln mit 100% bedeckung einer Klasse für die Estimation von Bevölkerung/Voloumen für jede Häuserklasse\\n3. Mergen des des Datensatzes \"Bevölkerung im 100m Gitter\" auf die Kacheln in Polygon Form\\n4. Berechnung der Bevölkerung pro Volumen für die Häuserklassen\\n5. Berechnung der Bevölkerung für jedes Haus über die Bevölkerung pro Volumen Beziehung\\n6. Aufsummieren der Bevölkerung pro Gitterzelle\\n7. Prozentuale Abweichung von geschätzter zu tatsächlicher Bevölkerung pro Gitterzelle berechnen\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Nils Weyrauch\n",
    "Skript für die Erstellung des Bevölkerungsrasters auf Basis der Häuserklassifikation\n",
    "\n",
    "Packages:\n",
    "Geopandas\n",
    "Pandas\n",
    "\n",
    "Aufbau:\n",
    "1. Ermittlung der prozentualen Anteile der Häuserklassen an den 100m Grid Zellen\n",
    "2. Identifizierung geeigneter Kacheln mit 100% bedeckung einer Klasse für die Estimation von Bevölkerung/Voloumen für jede Häuserklasse\n",
    "3. Mergen des des Datensatzes \"Bevölkerung im 100m Gitter\" auf die Kacheln in Polygon Form\n",
    "4. Berechnung der Bevölkerung pro Volumen für die Häuserklassen\n",
    "5. Berechnung der Bevölkerung für jedes Haus über die Bevölkerung pro Volumen Beziehung\n",
    "6. Aufsummieren der Bevölkerung pro Gitterzelle\n",
    "7. Prozentuale Abweichung von geschätzter zu tatsächlicher Bevölkerung pro Gitterzelle berechnen\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ffdca7-7862-419f-b60f-6e62c4162953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766ef3eb-adb9-4ef1-aa64-cdf77409ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funktion zur Ermittlung der prozentualen Häuserklassen Anteilen von den klassifizierten Häusern in Punktform in dem Polygonisierten 100m Grid für Deutschland\n",
    "\n",
    "Aufbau:\n",
    "1. Spatial Join der Punkte in jedes zugehörige Polygon\n",
    "2. Gruppieren der Daten pro Polygon und pro Klasse\n",
    "3. Berechnung der Prozentualen Anteile der jeweiligen Klasse an Gesamtzahl der Punkte in jedem Polygon\n",
    "4. Transformation der Daten, sodass jeder Polygon ID die entsprechenden Klassen Anteile zugeordnet sind\n",
    "5. Merge der Daten auf die ursprünglichen Polygon Daten sodass die Geometrien weiterhin vorhanden sind\n",
    "\"\"\"\n",
    "\n",
    "def calc_class_perc(poly_gdf, point_gdf, class_column):\n",
    "\n",
    "    #sjoin der Punkt Daten auf die zugehörigen Polygone\n",
    "    joined_data = poly_gdf.sjoin(point_gdf,how=\"left\", predicate=\"intersects\")\n",
    "    \n",
    "    # gruppieren der Daten nach Polygon index und Klassen, errechnen der Anzahl der Punkte pro Klasse\n",
    "    grouped_data = joined_data.groupby([\"id\", class_column]).size()\n",
    "    \n",
    "    # gruppierte Daten werden umgewandelt, Index des Polygons werden Reihen und zugehörige Klassen-Zählung pro Polygon zu Splaten, NaN Values werden durch 0 ersetzt \n",
    "    grouped_piv = grouped_data.unstack(fill_value=0)\n",
    "    \n",
    "    #aufsummieren der Punkt Anzahl pro Polygon (Axis=1)\n",
    "    point_sum = grouped_piv.sum(axis=1)\n",
    "\n",
    "    # Berechnen der Prozentualen Anteile jeder Klasse für jedes Polygon\n",
    "    piv_perc = grouped_piv.div(point_sum, axis=0) * 100\n",
    "\n",
    "    # Jede Spalte erhält einen eindeutigen Namen, da die Werte in col in float angegeben werden müssen die Spalten Namen umgenannt werden für Ansicht im GIS\n",
    "    piv_perc.columns = [f\"Klasse_{col}_perc\" for col in piv_perc.columns]\n",
    "    piv_perc = piv_perc.rename(columns={\"Klasse_1.0_perc\" : \"Klasse_1_perc\", \"Klasse_2.0_perc\" : \"Klasse_2_perc\", \"Klasse_3.0_perc\" : \"Klasse_3_perc\", \"Klasse_4.0_perc\": \"Klasse_4_perc\", \n",
    "                                          \"Klasse_5.0_perc\" : \"Klasse_5_perc\", \"Klasse_6.0_perc\" : \"Klasse_6_perc\", \"Klasse_7.0_perc\" : \"Klasse_7_perc\" , \"Klasse_8.0_perc\" : \"Klasse_8_perc\"})\n",
    "\n",
    "    # Erstellen der Spalte dom_class, welche angibt welche der class_perc Spalten den höchsten Prozentualen Wert enthält \n",
    "    # Die Prozent Spalten werden, mit iloc selektiert und in jeder Reihe wird der Spalten-Name des höchsten Wertes in der Spalte dom_class festgehalten\n",
    "    piv_perc[\"dom_class\"] = piv_perc.iloc[:, 0:8].apply(lambda x: x.idxmax(), axis=1)\n",
    "    \n",
    "    # idmax Funktion setzt den Namen der Spalte ein, die Spaltennamen werden per Mapping Dictionary durch die Klassen Werte ersetzt\n",
    "    rename_dic = {\"Klasse_1_perc\" : \"1\", \"Klasse_2_perc\" : \"2\", \"Klasse_3_perc\" : \"3\", \n",
    "                  \"Klasse_4_perc\": \"4\", \"Klasse_5_perc\" : \"5\", \"Klasse_6_perc\" : \"6\", \n",
    "                  \"Klasse_7_perc\" : \"7\" , \"Klasse_8_perc\" : \"8\"}\n",
    "    piv_perc[\"dom_class\"] = piv_perc[\"dom_class\"].map(rename_dic)\n",
    "    \n",
    "    # zurückmergen der Prozente an den ursprünglichen Datensatz um Geometrien wieder aufzunehmen\n",
    "    merged_ip_gdf = poly_gdf.merge(piv_perc, how=\"left\", left_on=\"id\", right_on=\"id\")\n",
    "\n",
    "    return merged_ip_gdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02929d27-a241-401c-99cf-fbbc0cb92be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funktion zur Verknüpfung der Gridzellen mit den Kreisen des UG\n",
    "Gridzellen werden Kreisen zugeordnet auf Basis der Gridzellen-Zentroide \n",
    "\n",
    "Aufbau:\n",
    "1. Umwandeln der Gridzellen zu Zentroiden (Punkten), sodass eindeutige Zuordnung möglich ist\n",
    "2. Spatial Join der UG Kreise auf die Gridzellen Zentroide\n",
    "3. Mergen der Abkürzungen für die kreise des UGs auf IP Datensatz der Gridzellen\n",
    "\"\"\"\n",
    "def assign_ug_kreis(pol_grid, pol_lk):\n",
    "\n",
    "    # Umwandeln der polygonisierten Grid-Zellen in Centroide, um diese eindeutig Kreisen zuordnen zu können \n",
    "    # vermeidet Probleme mit Zellen, die in mehreren Kreisen liegen\n",
    "    grid_centr = pol_grid.copy()\n",
    "    grid_centr[\"geometry\"] = grid_centr.geometry.centroid\n",
    "    \n",
    "    # Verknüpfung der Grid Zellen mit dem entsprechenden Landkreis, über einen spatial join\n",
    "    centr_sjoin = grid_centr.sjoin(pol_lk, how=\"left\", predicate=\"intersects\")\n",
    "    \n",
    "    # zurückmergen der Spalte mit den entsprechenden Landkreisen auf den ursprünglichen GDF\n",
    "    grid_lk = pol_grid.merge(centr_sjoin[\"GN_ID\"], how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "    return grid_lk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12c2b0e-6174-4bcc-b229-0a7063955e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "funktion Berechnet Kovariante Bev/Vol für manuell gescoutete Zellen\n",
    "\n",
    "Aufbau:\n",
    "1. Filtern der Datensatzes, nach Gebieten die in trai gelabelt wurden\n",
    "2. joinen der Häuser Daten auf die Grid Zelle\n",
    "3. Summieren der Häuservolumen pro Zelle\n",
    "4. Berechnung der Bev/Vol Beziehung der Zelle\n",
    "5. Datensatz in Pivot Tabelle umbauen, welche die durchschnittliche Bev/Vol Beziehung pro Klasse und LK im UG aufspaltet\n",
    "\"\"\"\n",
    "\n",
    "def calc_Bev_vol_trained(grid_gdf, point_gdf):\n",
    "\n",
    "    # Filter nach gelabelten Zellen\n",
    "    grid_filt = grid_gdf[grid_gdf[\"Train\"] == 1]\n",
    "\n",
    "    # Joinen der Häuserdaten in Punktform auf den Griddatensatz\n",
    "    grid_sjoin = grid_filt.sjoin(point_gdf, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "    # Berechnung der Gebäudevolumen pro Zelle, Ergebnisspalte bekommt Namen \"vol_sum\"\n",
    "    grid_vol_sum = grid_sjoin.groupby(\"id\")[\"vol_adr\"].sum().reset_index(name=\"vol_sum\")\n",
    "\n",
    "    # Die resultierende Series wird zurückgemergt\n",
    "    grid_sjoin = grid_sjoin.merge(grid_vol_sum, on=\"id\", how=\"left\")\n",
    "\n",
    "    # Berechnung der Einwohner pro summierten Volumen der Grid Zellen\n",
    "    grid_sjoin[\"bev_vol\"] = grid_sjoin[\"Einwohner\"] / grid_sjoin[\"vol_sum\"]\n",
    "\n",
    "    # Ergebnisse werden in eine Pivot Tabelle überführt die als Index die LK Namen besitzen und als Spalten die Bev/Vol pro Hausklasse\n",
    "    pivot = grid_sjoin.pivot_table(index=\"GN_ID\", columns=\"dom_class\", values=\"bev_vol\", aggfunc=\"mean\")\n",
    "\n",
    "    return pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f24d7b0-3b80-4402-b169-b1308a7f1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funktion zur Berechnung der Bev/Vol Beziehung über alle homogenen Häuser Grid Zellen, um unterschiede zu den ausgewählten Grid Zellen festzustellen\n",
    "\n",
    "Aufbau:\n",
    "1. Filtern der Datensatzes, nach Gebieten die 100 Prozent eine Häuserklasse aufweisen\n",
    "2. joinen der Häuser Daten auf die Grid Zelle\n",
    "3. Summieren der Häuservolumen pro Zelle\n",
    "4. Berechnung der Bev/Vol Beziehung der Zelle\n",
    "5. Datensatz in Pivot Tabelle umbauen, welche die durchschnittliche Bev/Vol Beziehung pro Klasse und LK im UG aufspaltet \n",
    "\"\"\"\n",
    "\n",
    "def calc_Bev_vol_mean(grid_gdf, point_gdf):\n",
    "\n",
    "    # Filtern des Datasets ob in den Werten (.any) der Spalten 8-15 die Prozentuale Anzahl 100 ist \n",
    "    # und ob die Einwohnerzahl 2011 in der Zelle verschlüsselt (-1) wurde, Zellen mit nur einem Haus werden ebenfalls rausgeschmissen um Verzerrungen zu vermeiden\n",
    "    grid_filt = grid_gdf[((grid_gdf.iloc[:, 8:16] == 100.0).any(axis=1)) & (grid_gdf[\"Einwohner\"] != -1) & (grid_gdf[\"House_Anz\"] > 1)]\n",
    "    \n",
    "    # Joinen der Häuserdaten in Punktform auf den Griddatensatz\n",
    "    grid_sjoin = grid_filt.sjoin(point_gdf, how=\"left\", predicate=\"intersects\")\n",
    "    \n",
    "    # Berechnung der Gebäudevolumen pro Zelle, Ergebnisspalte bekommt Namen \"vol_sum\"\n",
    "    grid_vol_sum = grid_sjoin.groupby(\"id\")[\"vol_adr\"].sum().reset_index(name=\"vol_sum\")\n",
    "    \n",
    "    # Die resultierende Series wird zurückgemergt\n",
    "    grid_sjoin = grid_sjoin.merge(grid_vol_sum, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Berechnung der Einwohner pro summierten Volumen der Grid Zellen\n",
    "    grid_sjoin[\"bev_vol\"] = grid_sjoin[\"Einwohner\"] / grid_sjoin[\"vol_sum\"]\n",
    "    \n",
    "    # Ergebnisse werden in eine Pivot Tabelle überführt die als Index die LK Namen besitzen und als Spalten die Bev/Vol pro Hausklasse\n",
    "    pivot = grid_sjoin.pivot_table(index=\"GN_ID\", columns=\"dom_class\", values=\"bev_vol\", aggfunc=\"mean\")\n",
    "\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e96831-eeb1-4269-9573-31abaa428af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funktion zur Zuweisung der Werte der pivot Tabelle mit den Bev/Vol Werten pro Landkreis des Untersuchungsgebiets zu den entsprechenden Häuserklassen\n",
    "Idee ist die Werte aus dem Häuser DF für die lokaliserung der Daten in der Pivot Tabelle zu nutzen. \n",
    "Die Werte entsprechenden den Feldern, in denen sich die richtigen Reihenwerte mit den richtigen Spaltenwerten überschneiden\n",
    "\n",
    "Aufbau:\n",
    "1. erste Schleife über Dataframe mit Häuserdaten, festlegen der zwei Spalten mit den Werten die den Reihen und Spalten der Pivot Tabelle entsprechen\n",
    "2. if clause festlegen, wenn Match in index und Spalte der Pivot Tabelle gefunden, dann setze Werte in Spalte des Häuserdataframes\n",
    "3. else clause festelgen, falls nicht gefunden\n",
    "\"\"\"\n",
    "\n",
    "def locate_val_piv(house_df, piv_bev_vol, op_column_name):\n",
    "\n",
    "    #Erstellen der bev_vol Spalte im house df\n",
    "    house_df[op_column_name] = 0.0\n",
    "\n",
    "    # Schleife über house_df\n",
    "    for index, row in house_df.iterrows():\n",
    "\n",
    "        #Reihen (Kreis ID) und Spalten Werte (Häuserklasse des RF) festlegen für piv_bev_vol df\n",
    "        row_val = row[\"GN_ID\"]\n",
    "        col_val = row[\"pred_int\"]\n",
    "\n",
    "        # If clause für die Erfüllung der zwei Bedingungen festlegen\n",
    "        if (row_val in piv_bev_vol.index) and (col_val in piv_bev_vol.columns):\n",
    "\n",
    "            # falls Bedingung erfüllt, weise entsprechenden Schnittpunkt Wert dem house_df zu\n",
    "            match_val = piv_bev_vol.loc[row_val, col_val]\n",
    "            house_df.loc[index, op_column_name] = match_val\n",
    "\n",
    "        # else clause festlegen um Fehler zu identifizieren\n",
    "        else:\n",
    "            house_df.loc[index, op_column_name] = float(\"NaN\")\n",
    "\n",
    "\n",
    "    return house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf0e5c0-6e0d-4925-925c-cb4fd9ec3af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funktion zur aufsummierung der geschätzten Hausbewohner pro Gridzelle\n",
    "\n",
    "Aufbau:\n",
    "1. Spatial Join der Häuser zu den jeweiligen Gridzellen\n",
    "2. Datensatz gruppieren pro Grid ID und aufsummieren des angegeben Felds für die Bevölkerungszahlen\n",
    "3. resultierende Series zurückmergen auf den GDF des grids per id\n",
    "4. prozentuale Abweichung von offiziellen Daten berechnen und in neuer Spalte festhalten\n",
    "\"\"\"\n",
    "\n",
    "def sum_bev_in_grid(grid_gdf, haus_gdf, ip_bev_column,op_bev_sum_column, op_perc_dif_column):\n",
    "\n",
    "    # Zuordnung der Häuser zu der jeweiligen Gridzelle\n",
    "    grid_sjoin = grid_gdf.sjoin(haus_gdf, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "    # Gruppieren des Datensatzes pro grid id, aufsummieren der Bevölkerungszahlen\n",
    "    grid_bev_sum = grid_sjoin.groupby(\"id\")[ip_bev_column].sum().reset_index(name=op_bev_sum_column)\n",
    "\n",
    "    # mergen der Bevölkerungszahlen auf IP grid_gdf\n",
    "    grid_gdf_merged = grid_gdf.merge(grid_bev_sum, on=\"id\", how=\"left\")\n",
    "\n",
    "    # Berechnung der prozentualen Abweichung von offiziellen zu geschätzen Werten\n",
    "    grid_gdf_merged[op_perc_dif_column] = (grid_gdf_merged[\"Einwohner\"] - grid_gdf_merged[op_bev_sum_column]) /grid_gdf_merged[\"Einwohner\"] * 100\n",
    "\n",
    "    return grid_gdf_merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d01e11-0d01-4365-bd20-232aeeb4eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funktion, welche den Gebäudeadressen das entsprechende Haus mit seinen Attributen zugewiesen wird. (analoges vorgehen zu Zensus Methodik)\n",
    "Für Häuser mit mehreren Adressen wird das Volumen durch die Anzahl der Häuser geteilt, um Berechnungen von Häusern mit mehreren Adressen in verschiedenen Gridzellen nicht zu verzerren\n",
    "\n",
    "Aufbau:\n",
    "1. Filtern der wichtigen Spalten\n",
    "2. Spatial Join der Hausattribute auf die Adresspunkte\n",
    "3. Gruppieren des Datensatzes pro Haus ID\n",
    "4. Zuordnung von neuer Volumen Spalte, welche aus Volumen/Anzahl der Häuser besteht\n",
    "\"\"\"\n",
    "\n",
    "def assign_house_attr(adress_gdf, house_gdf):\n",
    "\n",
    "    # Filtern des Datensatzes auf eindeutige Kennung und entsprechende Geometrien, field_2 hält die oid der Adressen\n",
    "    adress_filt = adress_gdf[[\"field_2\", \"geometry\"]]\n",
    "\n",
    "    # Joinen der Häuserattribute, inner join weil Häuser aus Datensatz entfernt wurden\n",
    "    adress_sjoin = adress_filt.sjoin(house_gdf, how=\"inner\", predicate=\"within\")\n",
    "    adress_sjoin.reset_index().drop_duplicates(\"index\", inplace=True)\n",
    "    \n",
    "    #umbennen der Spalte field_2 zu oid, droppen der Spalte index_right um Fehler bei weiteren Joins zu vermeiden\n",
    "    adress_sjoin.rename(columns={\"field_2\" : \"oid\"}, inplace=True)\n",
    "    adress_sjoin.drop(columns=[\"index_right\"], inplace=True)\n",
    "    \n",
    "    # Volumen der Häuser wird für jede Adresse durch Anzahl der Hausnummern geteilt und in neuer Spalte festgehalten\n",
    "    adress_sjoin[\"vol_adr\"] = adress_sjoin[\"VOL\"] / adress_sjoin[\"HK_ANZ\"]\n",
    "\n",
    "    return adress_sjoin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eef1188-e10d-441f-a58a-5f70c824a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_points_in_polygons(points, gdf, polygon_id=\"id\"):\n",
    "\n",
    "    # Zählen der Punkte in einem Polygon mittels räumlicher Verknüpfung, \n",
    "    # \"inner\" sorgt dafür, dass nur gezählt wird, falls Haus vorliegt, \n",
    "    # \"groupby\" gibt Attribut vor, für welches gezählt wird, hier: Häuseridentifier\n",
    "    # \"size\" gibt die Anzahl der Punkte pro gml_id an, neue Spalte wird umbenannt\n",
    "    point_per_pol = (gdf.sjoin(points, how=\"inner\", predicate=\"intersects\").groupby(polygon_id).size().rename(\"House_Anz\"))\n",
    "\n",
    "    # Merge der Häuser Anzahl auf die Gridzellen, für deren identifier \"id\"\n",
    "    # NoData/NAN werden mit 0 gefüllt\n",
    "    result_gdf = (gdf.merge(point_per_pol,on=polygon_id, how=\"left\").fillna({\"House_Anz\": 0}))\n",
    "\n",
    "    return result_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3991ebe-4b46-41df-ad7a-ab7467e83bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funktion, welche den Identifier des Grids von 2022 in die Form des identifiers von dem Griddatensatz bringt\n",
    "\n",
    "Aufbau:\n",
    "slicen des Datensatzes sodass, Präfix CRS3035RES wegfällt, und 2 Stellen bei der Koordinatenbenennung\n",
    "\"\"\"\n",
    "\n",
    "def transform_identifier(identifier):\n",
    "   \n",
    "    # CRS3035RES fallenlassen\n",
    "    identifier = identifier[10:]\n",
    "    \n",
    "    # Position von N und E Koordinaten feststellen für weiteren slice\n",
    "    n_pos = identifier.find('N')\n",
    "    e_pos = identifier.find('E')\n",
    "    \n",
    "    # Listen so slicen, dass die Parts die behaltem werden sollen, nur noch addiert werden müssen, immer die 5 Zahlen nach den Buchstaben\n",
    "    part1 = identifier[:n_pos + 6]  \n",
    "    part2 = identifier[e_pos:e_pos + 6]\n",
    "    \n",
    "    # identifier zusammenbringen\n",
    "    new_identifier = part1 + part2\n",
    "    \n",
    "    return new_identifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ccc2d03-879a-4494-aded-ec956d383419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\Nils\\AppData\\Local\\Temp\\ipykernel_9684\\4029157439.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nPotenzieller Workflow des umwandeln der Gridzellen in UTM 32N und zuschnitt auf UG\\nwurde nicht verwendet aufgrund zu hoher Anforderungen an den Computer \\n\\ngrid = gpd.read_file(r\"D:@m Grid DE\\\\DE_Grid_ETRS89-LAEA_100m\\\\geogitter\\\\DE_Grid_ETRS89-LAEA_100m.gpkg\")\\n\\n# umwandeln des Koordinatensystems von ganzeuropäisch genormten, auf das passende für das UG\\ngrid_reproj = grid.to_crs(epsg=25832)\\n\\n# Auswahl der Gridzellen, welche teilweise in UG liegen\\ngrid_ug = grid_reproj[grid_reproj.geometry.intersects(UG_kreise.unary_union)]\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Potenzieller Workflow des umwandeln der Gridzellen in UTM 32N und zuschnitt auf UG\n",
    "wurde nicht verwendet aufgrund zu hoher Anforderungen an den Computer \n",
    "\n",
    "grid = gpd.read_file(r\"D:\\100m Grid DE\\DE_Grid_ETRS89-LAEA_100m\\geogitter\\DE_Grid_ETRS89-LAEA_100m.gpkg\")\n",
    "\n",
    "# umwandeln des Koordinatensystems von ganzeuropäisch genormten, auf das passende für das UG\n",
    "grid_reproj = grid.to_crs(epsg=25832)\n",
    "\n",
    "# Auswahl der Gridzellen, welche teilweise in UG liegen\n",
    "grid_ug = grid_reproj[grid_reproj.geometry.intersects(UG_kreise.unary_union)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c0f6ab1-0030-4c26-a7d6-c7a168ffae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Daten, grid = 100m Grid, RF_Haus = Ergebnisse der Random Forest Klassifikation\n",
    "# geb_ref = georeferenzierte Adressen des UG\n",
    "\n",
    "grid = gpd.read_file(r\"F:\\Basisdaten\\grid_laea_ug_reproj.shp\", crs=\"EPSG:25832\")\n",
    "RF_Haus = gpd.read_file(r\"F:\\Zwischendaten\\RF_Results.shp\", crs=\"EPSG:25832\")\n",
    "geb_ref = gpd.read_file(r\"F:\\Basisdaten\\Geb_ref_UG.shp\", crs=\"EPSG:25832\")\n",
    "\n",
    "#Herausfiltern von Häusern im Gebäudedatensat, welche zum Zeitpunkt der Höhenmodellaufnahme noch nicht da waren und dementsprechend kein Volumne besitzen (ca. 76)\n",
    "Haus_filt = RF_Haus[RF_Haus[\"VOL\"] != 0]\n",
    "\n",
    "ip_kreise = gpd.read_file(r\"F:\\Basisdaten\\dvg1krs_nw.shp\", crs=\"EPSG:25832\")\n",
    "UG_kreise = ip_kreise[ip_kreise['GN'].isin([ \"Ennepe-Ruhr-Kreis\",  \"Oberbergischer Kreis\", \"Wuppertal\", \"Remscheid\" ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba0dd7b2-79bd-45b1-9710-93db701bdc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des ursprünglichen Hausdatensatzes, welcher später eine zuordnung der Gebäudefunktion erlaubt\n",
    "ALKIS_house = gpd.read_file(r\"F:\\Zwischendaten\\Data_Hausmerkmale.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6754fb85-3136-4fcb-88d4-f02936d5cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aus Datensatz gefilterte Hochhäuser wieder einbringen\n",
    "hochhaus = gpd.read_file(r\"F:\\Zwischendaten\\hochhaus.shp\", crs=\"EPSG:25832\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f9a47e-b6b4-459d-aa73-8a31a881be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Da Hochhäuser nicht häufig genug vorhanden sind um eigene Werte zu entwickeln, werden diese zu Klasse 7 (Plattenbauten) reklassifiziert, \n",
    "#da deren strukturelle Merkmale denen der Hochhäuser am meisten ähneln\n",
    "hochhaus[\"PREDICTED\"] = 7.0\n",
    "hochhaus[\"VOL\"] = hochhaus[\"vol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fb458d-f316-4dcc-96ea-99333e0bbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# um Spalten zu vermeiden die überflüssig sind, check auf die Überschneidung und nur verschnitt dieser\n",
    "inters_col = Haus_filt.columns.intersection(hochhaus.columns)\n",
    "haus_inters = Haus_filt[inters_col]\n",
    "hochhaus_inters = hochhaus[inters_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28e718f2-8d67-4bef-a261-da88129ef70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hochhäuser werden an Klassifizierten Datensatz angehängt\n",
    "Haus = pd.concat([haus_inters, hochhaus_inters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85170394-47c7-4619-9d61-a60bfaa0de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des Datensatzes Bevölkerung im 100m Gitter (.csv) und umwandlung in einen Dataframe\n",
    "bev_grid = pd.read_csv(r\"F:\\Basisdaten\\Zensus2022_Bevoelkerungszahl_100m-Gitter.csv\", sep=\";\")\n",
    "bev_grid_df = pd.DataFrame(bev_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c59fb0cf-e7f2-44b9-b34c-85dd32970a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuen Identifier dem alten anpassen\n",
    "bev_grid_df['GITTER_ID_100m'] = bev_grid_df['GITTER_ID_100m'].apply(transform_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1662399-9418-4c1e-89e6-5711ca330d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herausfiltern von Duplikaten, Normalize stellt sicher, dass das Filterung richtig funktioniert, indem es die Polygon Vertices Reihenfolgen einheitlich ordnet,\n",
    "ALKIS_house.normalize()\n",
    "ALKIS_clean = ALKIS_house.drop_duplicates(subset='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a4c8554-9b26-47ea-a109-32886001da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Haus.normalize()\n",
    "haus_clean = Haus.drop_duplicates(\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db4b80a2-be4a-4f91-b907-490665bafd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtern des Datensatzes auf die relevanten Spalten, und zur vermeidung von Dopplung bei Sjoin\n",
    "ALKIS_house_filt = ALKIS_clean[[\"gml_id\", \"gebaeudefu\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a05c5104-5c70-4a56-8189-300398b60d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sjoin der Haus Punkte, um die Gebäudefunktion und gml_id der Gebäude, welche während der RF Klassifikation verloren gehen,\n",
    "# wieder den Häusern zuzuweisen, erlaubt später Korrektur Faktor zu nutzen für Häuser die neben einer Wohnnutzung auch eine \n",
    "# wirtschaftliche Nutzung aufweisen\n",
    "Haus_gebfun = gpd.sjoin(haus_clean, ALKIS_house_filt, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "#Sjoin ordnet nicht eins zu eins zu, Duplikate die durch Join entstanden sind werden gefiltert\n",
    "Haus_gebf_dupl = Haus_gebfun.reset_index().drop_duplicates(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fcdd4c8-21ea-4755-acb7-e2436a37c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vermeidet Fehler bei zukünfitgen Joins, wenn das Feld Index_right gedroppt wird\n",
    "Haus_gebf_dupl.drop(columns=[\"index\"], inplace=True)\n",
    "Haus_gebf_dupl.drop(columns=[\"index_right\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4015b3c-1252-4452-aaa6-1081c9a281f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\anaconda3\\envs\\geopandas\\Lib\\site-packages\\geopandas\\geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Anlegen einer Abkürzungsspalte für die Namen der Landkreise\n",
    "# erlaubt später Zuordnung der Grid Zellen zu einem Gemeinde Gebiet per Funktion\n",
    "LK_ID = {\"Remscheid\" : \"RS\", \"Wuppertal\" : \"WU\", \"Oberbergischer Kreis\" : \"OBK\", \"Ennepe-Ruhr-Kreis\" : \"ERK\"}\n",
    "UG_kreise[\"GN_ID\"] = UG_kreise[\"GN\"].map(LK_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3a04a53-0c54-4ce3-8d76-edfaac28b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuweisen der Häuserattribute auf die entsprechenden Adresspunkte, \n",
    "# nötig um die selben Punkte zur Hochrechnung der Bevölkerung zu nutzen wie statistisches Bundesamt\n",
    "adr_point = assign_house_attr(geb_ref, Haus_gebf_dupl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c80d570c-5c6f-4d36-ba01-396d8de28ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# den adressen wird ihrer lage entsprechend der richtige Landkreis zugeordnet\n",
    "adr_point_GN = assign_ug_kreis(adr_point, UG_kreise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58d906f7-c7a3-41b1-87b7-dc2e6767f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalkulation der prozentualen Anteile der RF klassifizierten Häuser an jeder Gridzelle um homogene Gebiete zu identifizieren\n",
    "perc = calc_class_perc(grid, adr_point, \"PREDICTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b37de135-0a23-4467-98bb-7546735d9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallen lassen von Spalten, die nicht benötigt werden\n",
    "drop_col = [\"featuretyp\", \"dataset_na\", \"f_staat\", \"f_land\", \"f_wasser\", \"p_staat\", \"p_land\", \"p_wasser\", \"Shape_Leng\", \"Shape_Area\",\"OBJECTID\"]\n",
    "perc_cl = perc.drop(columns=drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11465d38-8557-4fec-b14b-d04cce338c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mergen der Datensätze mit prozentualen Anteilen der Häuserklassen und der Bevölkerung pro Gridzelle\n",
    "grid_perc_bev = perc_cl.merge(bev_grid_df, how=\"inner\", left_on=\"id\", right_on=\"GITTER_ID_100m\")\n",
    "# Aussortieren der Kacheln, die aufgrund von Datenschutz verschlüsselt sind oder nicht bewohnt sind\n",
    "grid_perc_bev = grid_perc_bev[grid_perc_bev[\"Einwohner\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54fbb9f3-d8d5-4185-9f7d-6de8953e9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuordnung der Gridzelle, zu dem jeweiligen Landkreis, in dem sich die Gridzellen Mitte befindet\n",
    "grid_perc_GN = assign_ug_kreis(grid_perc_bev, UG_kreise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "946fcba0-e2b9-4c24-af39-b06a3c7a333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zählen der Häuser in jeder Gridzelle \n",
    "grid_perc_count = count_points_in_polygons(adr_point, grid_perc_GN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3871612-57e0-47ec-ac3e-e64cfa409e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\AppData\\Local\\Temp\\ipykernel_9684\\162236167.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  grid_perc_count.to_file(r\"F:\\Zwischendaten\\grid_ug_perc_2022.shp\")\n"
     ]
    }
   ],
   "source": [
    "grid_perc_count.to_file(r\"F:\\Zwischendaten\\grid_ug_perc_2022.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b487a0c-a58c-480c-8818-a11d3c032198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Berechnung der Bevölkerung / Volumen Beziehung für jede Gridzelle die 100 Prozent eine Häuserklasse aufweist\n",
    "# erlaubt spätere Gegenüberstellung mit manuell gescouteten Gebieten\n",
    "bev_vol_mean = calc_Bev_vol_mean(grid_perc_count, adr_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4f29310-3525-40bc-9522-6ce0f21ac97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dom_class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GN_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERK</th>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBK</th>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dom_class         1         2         3         5         6         7  \\\n",
       "GN_ID                                                                   \n",
       "ERK        0.000982  0.001097  0.001265  0.001233  0.001260  0.001301   \n",
       "OBK        0.000957  0.000962  0.001160  0.001023  0.001086  0.001173   \n",
       "RS         0.001016  0.001026  0.001340  0.001199  0.001324  0.001465   \n",
       "WU         0.000981  0.001069  0.001308  0.001092  0.001495  0.001503   \n",
       "\n",
       "dom_class         8  \n",
       "GN_ID                \n",
       "ERK        0.001217  \n",
       "OBK        0.000754  \n",
       "RS         0.001135  \n",
       "WU         0.001208  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bev_vol_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4abbb885-a601-4739-9cc1-1c160858ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export der Pivot Tabelle, die die durchschnittliche Bev/Vol Beziehung angibt\n",
    "bev_vol_mean.to_csv(r\"F:\\Zwischendaten\\pivot_bev_vol_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74591c6a-9100-410b-9f46-5f39d7a77a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuweisen der Landkreis IDs auf die Häuser über das Grid (sodass Zuordnung von Haus und Grid zu selbem LK gewährleistet ist) \n",
    "# für Zuordnung von regional spezifischen Werten, der index den die Funktion Sjoin automatisch erstellt, wird gedropt\n",
    "haus_gn = adr_point.sjoin(grid_perc_GN[[\"geometry\",\"GN_ID\"]], how=\"left\", predicate=\"intersects\").drop(columns=\"index_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bc8571e-7183-4bfb-9c14-f4defd73329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "haus_gn[\"pred_int\"] = haus_gn[\"PREDICTED\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6edf282-e655-4344-8ecc-719502c62d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# umwandeln der Spalten Namen zu Integern der bev_vol_mean Spaltennamen, da sonst zuordnung mit den Integer Werten der Daten nicht funktioniert\n",
    "bev_vol_mean.columns = bev_vol_mean.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdcdff5d-ba00-4abd-84ef-af42e29294d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuordnen des regionalen Bev/Vol Wert für die Ergebnisse der RF Klassifikation\n",
    "haus_bev = locate_val_piv(haus_gn, bev_vol_mean, \"bev_vol_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00dd2fa2-9033-4dc0-bfb0-49fc1766afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hochrechnung der Anzahl der Hausbewohner auf Basis des Volumens pro Adresse und der Bev/Vol Beziehung der homogenen Kacheln\n",
    "haus_bev[\"Bev_Haus_m\"] = haus_bev[\"vol_adr\"] * haus_bev[\"bev_vol_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5b94c6c-b7cb-4ebe-acf1-1af312acc26d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Einbezug eines Korrektur Faktors für Gebäude, welche nicht nur Wohnnutzung aufweisen über das Attribut \"gebaeudefun\"\n",
    "# nummern in Liste stehen für alle Attribut Werte, welche mit Wohn und wirtschaftliche Nutzung ausgewiesen sind ca. 18 000\n",
    "\n",
    "for index, row in haus_bev.iterrows():\n",
    "    if row[\"gebaeudefu\"] in [1110, 1120, 1121, 1122, 1123, 1130, 1131, 2310, 2320]:\n",
    "        haus_bev.at[index, \"Bev_Haus_m\"] *= 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "132a5b8b-056b-41ea-bb9e-cb41b78ed22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufsummieren der Anzahl der geschätzten Hausbewohner pro Gridzelle und Berechnung der Abweichung\n",
    "grid_bev_abw_m = sum_bev_in_grid(grid_perc_count, haus_bev, \"Bev_Haus_m\", \"m_pred_bev_sum\", \"dif_bev_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58dce668-a85c-496c-9a30-6c1cabd8354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export des grids um Zellen zu identifizieren die für zweite Modell Variante geeignet sind\n",
    "#grid_bev_abw_m.to_file(F:\\Zwischendaten\\grid_bev_abw_2022.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19b13747-e762-455c-89b7-24765998aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Bevölkerung/Volumen Beziehung auf Basis ausgesuchter Gridzellen ohne Fehlerhafte Klassifikationen zum Vergleich mit den über den durchschnitt ermittelten Bevölkerungs-Volumen Beziehung\n",
    "\n",
    "# Import der gesichteten Gridzelle, welche mit dem Feld \"Trained\" gekennzeichnet wurden\n",
    "grid_trained = gpd.read_file(r\"F:\\Zwischendaten\\grid_ug_perc_trained.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04267eb4-eef3-45f7-a587-b4774ceacea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da die Sichtung der Zellen für das Trained Modell auf Basis des 2011 grids erfolgte, müssen die gescouteten Zellen auf den aktualisierten Datensatz gemergt werden\n",
    "grid_trained_new = grid_bev_abw_m.merge(grid_trained[[\"Gitter_ID_\",\"Train\"]], left_on=\"GITTER_ID_100m\", right_on=\"Gitter_ID_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f3b0fa2-32f0-4d05-bcf8-72b56a1b198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Bevölkerung-Volumen Beziehung für die trainierten Gridzellen\n",
    "bev_vol_trained = calc_Bev_vol_trained(grid_trained_new, adr_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d05d713-b6e1-451d-9fd6-59b0cdb33211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export der Pivot Tabelle zum Vergleich mit den über den Durchschnitt ermittelten Daten\n",
    "bev_vol_trained.to_csv(r\"F:\\Zwischendaten\\pivot_bev_vol_trained_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "010a6ed7-25c6-4087-a632-7c35a2c6b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# umwandeln der Spalten Namen zu Integern der bev_vol_mean Spaltennamen, da sonst zuordnung mit den Integer Werten der Daten nicht funktioniert\n",
    "bev_vol_trained.columns = bev_vol_trained.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "255fc9b1-60c3-4eb2-bac3-1caae32e28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zuordnen des regionalen Bev/Vol Wert für die Ergebnisse der RF Klassifikation\n",
    "haus_bev = locate_val_piv(haus_gn, bev_vol_trained, \"bev_vol_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf0d9f10-8e20-4f48-b3a3-0d0c803deaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hochrechnung der Anzahl der Hausbewohner auf Basis des Volumens pro Adresse und der Bev/Vol Beziehung der trainierten Kacheln\n",
    "haus_bev[\"Bev_Haus_t\"] = haus_bev[\"vol_adr\"] * haus_bev[\"bev_vol_trained\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28b7dc77-7ab0-46d5-ae84-3579f45ed7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einbezug eines Korrektur Faktors für Gebäude, welche nicht nur Wohnnutzung aufweisen über das Attribut \"gebaeudefun\"\n",
    "# nummern in Liste stehen für alle Attribut Werte, welche mit Wohn und wirtschaftliche Nutzung ausgewiesen sind ca. 18 000\n",
    "\n",
    "for index, row in haus_bev.iterrows():\n",
    "    if row[\"gebaeudefu\"] in [1110, 1120, 1121, 1122, 1123, 1130, 1131, 2310, 2320]:\n",
    "        haus_bev.at[index, \"Bev_Haus_t\"] *= 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05ab7784-7479-41e4-8053-2d940dcae88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufsummieren der Anzahl der geschätzten Hausbewohner pro Gridzelle und Berechnung der Abweichung für die trainierten Kacheln\n",
    "grid_bev_abw_t = sum_bev_in_grid(grid_perc_count, haus_bev, \"Bev_Haus_t\", \"t_pred_bev_sum\", \"dif_bev_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7dcaf538-505d-478a-bdaa-ffeb586b6e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergen der beiden Datensätze mit den verschiedenen Bevölkerungsschätzungen, um diese im folgenden zusammenzufassen und auszuwerten\n",
    "grid_bev_abw = grid_bev_abw_m.merge(grid_bev_abw_t[[\"id\", \"t_pred_bev_sum\", \"dif_bev_t\"]], on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16af519e-d80e-45e7-bcb9-fd919dfa20d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\AppData\\Local\\Temp\\ipykernel_9684\\3356142617.py:2: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  grid_bev_abw.to_file(r\"F:\\Zwischendaten\\grid_bev_abw_merge_2022.shp\")\n"
     ]
    }
   ],
   "source": [
    "# Export der Daten\n",
    "grid_bev_abw.to_file(r\"F:\\Zwischendaten\\grid_bev_abw_merge_2022.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4988763-0344-492d-ae3a-876e27c17efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_point_GN.to_file(r\"F:\\Zwischendaten\\adr_point.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f18a07-3ce0-435c-af3a-09c169f3eed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e0347-0918-404a-9bcd-cd6297f483ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0afe4-471a-447f-8425-efc72e59e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
